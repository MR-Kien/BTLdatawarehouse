# import streamlit as st
# import pandas as pd
# import numpy as np
# import joblib
# import plotly.express as px

# # 1. C·∫§U H√åNH TRANG
# st.set_page_config(page_title="D·ª± ƒëo√°n h√†nh vi mua h√†ng", layout="wide")

# st.title("üõçÔ∏è H·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m ti·∫øp theo (Bayes)")
# st.markdown("D·ª± ƒëo√°n **Category** kh√°ch h√†ng s·∫Ω mua d·ª±a tr√™n giao d·ªãch v·ª´a th·ª±c hi·ªán.")

# # 2. LOAD MODEL ƒê√É TRAIN
# @st.cache_resource
# def load_model():
#     # Load file .pkl b·∫°n ƒë√£ t·∫£i t·ª´ Kaggle v·ªÅ
#     artifacts = joblib.load('bayes_recommendation_model.pkl')
#     return artifacts

# try:
#     artifacts = load_model()
#     model = artifacts['model']
#     enc = artifacts['feature_encoder']
#     le = artifacts['label_encoder']
#     feature_names = artifacts['feature_names']
# except FileNotFoundError:
#     st.error("Kh√¥ng t√¨m th·∫•y file 'bayes_recommendation_model.pkl'. H√£y copy file model v√†o c√πng th∆∞ m·ª•c v·ªõi file app.py")
#     st.stop()

# # 3. T·∫†O GIAO DI·ªÜN NH·∫¨P LI·ªÜU (SIDEBAR)
# st.sidebar.header("Th√¥ng tin giao d·ªãch hi·ªán t·∫°i")

# input_data = {}

# # T·ª± ƒë·ªông t·∫°o Selectbox d·ª±a tr√™n d·ªØ li·ªáu ƒë√£ h·ªçc t·ª´ Encoder
# # enc.categories_ ch·ª©a danh s√°ch c√°c gi√° tr·ªã unique c·ªßa t·ª´ng c·ªôt l√∫c train
# for i, col_name in enumerate(feature_names):
#     options = list(enc.categories_[i])
#     input_data[col_name] = st.sidebar.selectbox(f"Ch·ªçn {col_name}", options)

# # 4. D·ª∞ ƒêO√ÅN
# if st.sidebar.button("D·ª± ƒëo√°n h√†nh vi ti·∫øp theo"):
#     # Chuy·ªÉn input th√†nh DataFrame
#     input_df = pd.DataFrame([input_data])
    
#     # M√£ h√≥a d·ªØ li·ªáu ƒë·∫ßu v√†o (d√πng encoder ƒë√£ load)
#     input_encoded = enc.transform(input_df)
    
#     # D·ª± ƒëo√°n class (nh√£n)
#     pred_idx = model.predict(input_encoded)
#     pred_label = le.inverse_transform(pred_idx)[0]
    
#     # D·ª± ƒëo√°n x√°c su·∫•t (cho bi·ªÉu ƒë·ªì)
#     proba = model.predict_proba(input_encoded)[0]
    
#     # T·∫°o DataFrame k·∫øt qu·∫£ x√°c su·∫•t
#     proba_df = pd.DataFrame({
#         'Category': le.classes_,
#         'Probability': proba
#     }).sort_values(by='Probability', ascending=False)

#     # 5. HI·ªÇN TH·ªä K·∫æT QU·∫¢
#     col1, col2 = st.columns([1, 2])
    
#     with col1:
#         st.success(f"Kh√°ch h√†ng c√≥ kh·∫£ nƒÉng cao nh·∫•t s·∫Ω mua:")
#         st.metric(label="Next Category", value=pred_label)
#         st.write(f"ƒê·ªô tin c·∫≠y: **{proba_df.iloc[0]['Probability']*100:.1f}%**")
        
#     with col2:
#         st.subheader("Ph√¢n ph·ªëi x√°c su·∫•t c√°c nh√≥m h√†ng")
#         # V·∫Ω bi·ªÉu ƒë·ªì c·ªôt b·∫±ng Plotly
#         fig = px.bar(
#             proba_df, 
#             x='Category', 
#             y='Probability', 
#             color='Probability',
#             color_continuous_scale='Blues',
#             text_auto='.1%'
#         )
#         st.plotly_chart(fig, use_container_width=True)
        
#     # Gi·∫£i th√≠ch th√™m (Optional - Gi·∫£ l·∫≠p c√¢y Bayes ƒë∆°n gi·∫£n)
#     with st.expander("üîç Chi ti·∫øt ph√¢n t√≠ch Bayes"):
#         st.write("M√¥ h√¨nh Naive Bayes t√≠nh to√°n x√°c su·∫•t d·ª±a tr√™n c√°c y·∫øu t·ªë b·∫°n ƒë√£ ch·ªçn:")
#         st.json(input_data)
#         st.write("D·ª±a tr√™n l·ªãch s·ª≠ d·ªØ li·ªáu, ƒë√¢y l√† t·ª∑ l·ªá ph·∫ßn trƒÉm kh·∫£ nƒÉng chuy·ªÉn ƒë·ªïi sang c√°c nh√≥m h√†ng kh√°c.")

# else:
#     st.info("üëà Vui l√≤ng ch·ªçn th√¥ng tin b√™n tr√°i v√† b·∫•m n√∫t 'D·ª± ƒëo√°n'")
# import streamlit as st
# import pandas as pd
# import numpy as np
# import joblib
# import plotly.express as px

# # 1. C·∫§U H√åNH TRANG
# st.set_page_config(page_title="D·ª± ƒëo√°n h√†nh vi mua h√†ng", layout="wide")

# st.title("üõçÔ∏è H·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m ti·∫øp theo")
# st.markdown("D·ª± ƒëo√°n **Category** kh√°ch h√†ng s·∫Ω mua d·ª±a tr√™n giao d·ªãch v·ª´a th·ª±c hi·ªán.")

# # 2. LOAD MODEL ƒê√É TRAIN
# @st.cache_resource
# def load_model():
#     try:
#         # ∆Øu ti√™n load model CatBoost (n·∫øu c√≥)
#         artifacts = joblib.load('catboost_gpu_model_v2.pkl')
#         return artifacts
#     except FileNotFoundError:
#         try:
#             # Fallback sang model c≈©
#             artifacts = joblib.load('bayes_recommendation_model.pkl')
#             return artifacts
#         except FileNotFoundError:
#             return None

# artifacts = load_model()

# if artifacts is None:
#     st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file model (.pkl).")
#     st.warning("Vui l√≤ng t·∫£i file model (v√≠ d·ª•: catboost_gpu_model_v2.pkl) v√† ƒë·∫∑t c√πng th∆∞ m·ª•c v·ªõi file app.py")
#     st.stop()

# model = artifacts['model']
# # L·∫•y c√°c th√†nh ph·∫ßn kh√°c (ch·∫•p nh·∫≠n None n·∫øu d√πng CatBoost)
# enc = artifacts.get('feature_encoder') 
# le = artifacts['label_encoder']
# feature_names = artifacts.get('feature_names', [
#     'current_category', 'current_subcategory', 'current_articletype', 
#     'customer_gender', 'age_group', 'province'
# ])
# model_type = artifacts.get('model_type', 'naive_bayes')

# # 3. T·∫†O GIAO DI·ªÜN NH·∫¨P LI·ªÜU (SIDEBAR)
# st.sidebar.header("Th√¥ng tin giao d·ªãch hi·ªán t·∫°i")

# # Dictionary ƒë·ªïi t√™n c·ªôt sang Ti·∫øng Vi·ªát
# column_alias = {
#     'current_category': 'Danh m·ª•c ch√≠nh',
#     'current_subcategory': 'Danh m·ª•c ph·ª•',
#     'current_articletype': 'Lo·∫°i s·∫£n ph·∫©m chi ti·∫øt',
#     'customer_gender': 'Gi·ªõi t√≠nh',
#     'age_group': 'Nh√≥m tu·ªïi',
#     'province': 'T·ªânh th√†nh'
# }

# # --- D·ªÆ LI·ªÜU M·∫™U ƒê·∫¶Y ƒê·ª¶ (ƒê√£ l√†m s·∫°ch kho·∫£ng tr·∫Øng) ---
# sample_data = {
#     'current_category': [
#         'accessories', 'apparel', 'personal care', 'footwear', 'free items', 'sporting goods', 'home'
#     ],
#     'current_subcategory': sorted([
#         'belts', 'topwear', 'shoe accessories', 'nails', 'bags', 'fragrance', 'gloves', 'shoes', 'flip flops', 
#         'watches', 'jewellery', 'socks', 'bottomwear', 'innerwear', 'sandal', 'lips', 'headwear', 'saree', 
#         'eyewear', 'ties', 'dress', 'free gifts', 'scarves', 'stoles', 'wallets', 'loungewear and nightwear', 
#         'apparel set', 'cufflinks', 'makeup', 'skin', 'skin care', 'accessories', 'hair', 'wristbands', 'eyes', 
#         'umbrellas', 'perfumes', 'bath and body', 'water bottle', 'sports accessories', 'mufflers', 
#         'sports equipment', 'vouchers', 'beauty accessories', 'home furnishing'
#     ]),
#     'current_articletype': sorted([
#         'belts', 'tshirts', 'shoe accessories', 'kurtas', 'nail polish', 'handbags', 'perfume and body mist', 
#         'gloves', 'casual shoes', 'flip flops', 'backpacks', 'sports shoes', 'watches', 'ring', 'socks', 
#         'salwar', 'necklace and chains', 'briefs', 'sandals', 'shirts', 'mobile pouch', 'formal shoes', 
#         'sports sandals', 'clutches', 'lipstick', 'caps', 'heels', 'lip liner', 'deodorant', 'track pants', 
#         'sarees', 'jackets', 'sweaters', 'tops', 'suspenders', 'sweatshirts', 'sunglasses', 'jeggings', 
#         'lip gloss', 'dresses', 'capris', 'trunk', 'free gifts', 'scarves', 'jeans', 'laptop bag', 'leggings', 
#         'trousers', 'dupatta', 'stoles', 'tunics', 'earrings', 'wallets', 'innerwear vests', 'flats', 'pendant', 
#         'night suits', 'kurta sets', 'bra', 'clothing set', 'cufflinks', 'swimwear', 'shorts', 
#         'highlighter and blush', 'nightdress', 'kurtis', 'bangle', 'eyeshadow', 'messenger bag', 
#         'face moisturisers', 'tablet sleeve', 'face wash and cleanser', 'kajal and eyeliner', 'skirts', 
#         'fragrance gift set', 'patiala', 'accessory gift set', 'hair colour', 'compact', 'boxers', 'tracksuits', 
#         'concealer', 'lounge shorts', 'lounge tshirts', 'wristbands', 'rain jacket', 'rucksacks', 'tights', 
#         'hat', 'duffel bag', 'baby dolls', 'foundation and primer', 'bracelet', 'jewellery set', 'suits', 
#         'travel accessory', 'lounge pants', 'mascara', 'umbrellas', 'eye cream', 'sunscreen', 'waistcoat', 
#         'bath robe', 'nehru jackets', 'booties', 'body lotion', 'mask and peel', 'camisoles', 'lip care', 
#         'stockings', 'toner', 'rompers', 'churidar', 'water bottle', 'face scrub and exfoliator', 'mufflers', 
#         'basketballs', 'footballs', 'salwar and dupatta', 'shapewear', 'nail essentials', 'shrug', 'shoe laces', 
#         'jumpsuit', 'ties and cufflinks', 'hair accessory', 'ipad', 'waist pouch', 'lip plumper', 
#         'body wash and scrub', 'rain trousers', 'beauty accessory', 'makeup remover', 'robe', 'headband', 
#         'mens grooming kit', 'key chain', 'face serum and gel', 'trolley bag', 'blazers', 'lehenga choli', 
#         'cushion covers'
#     ]),
#     'customer_gender': ['M', 'F'],
#     'age_group': ['1', '2', '3', '4', 'u'], # ƒê√£ s·∫Øp x·∫øp l·∫°i
#     'province': sorted([
#         'ACEH', 'BALI', 'BANGKA BELITUNG', 'BANTEN', 'BENGKULU', 'GORONTALO', 'JAKARTA RAYA', 'JAMBI', 
#         'JAWA BARAT', 'JAWA TENGAH', 'JAWA TIMUR', 'KALIMANTAN BARAT', 'KALIMANTAN SELATAN', 'KALIMANTAN TENGAH', 
#         'KALIMANTAN TIMUR', 'KEPULAUAN RIAU', 'LAMPUNG', 'MALUKU', 'MALUKU UTARA', 'NUSA TENGGARA BARAT', 
#         'NUSA TENGGARA TIMUR', 'PAPUA', 'PAPUA BARAT', 'RIAU', 'SULAWESI BARAT', 'SULAWESI SELATAN', 
#         'SULAWESI TENGAH', 'SULAWESI TENGGARA', 'SULAWESI UTARA', 'SUMATERA BARAT', 'SUMATERA SELATAN', 
#         'SUMATERA UTARA', 'YOGYAKARTA'
#     ])
# }

# input_data = {}

# # H√†m l√†m s·∫°ch hi·ªÉn th·ªã
# def clean_display_text(text):
#     return str(text).strip().title()

# # V√íNG L·∫∂P T·∫†O INPUT
# for col_name in feature_names:
#     display_name = column_alias.get(col_name, col_name)
    
#     # ∆Øu ti√™n l·∫•y options t·ª´ Encoder (n·∫øu c√≥ - tr∆∞·ªùng h·ª£p Naive Bayes)
#     if enc and hasattr(enc, 'categories_'):
#         # T√¨m index c·ªßa c·ªôt trong encoder
#         try:
#             # L∆∞u √Ω: feature_names ph·∫£i kh·ªõp th·ª© t·ª± v·ªõi encoder
#             idx = feature_names.index(col_name) 
#             options = list(enc.categories_[idx])
#         except:
#             options = sample_data.get(col_name, [])
#     else:
#         # Tr∆∞·ªùng h·ª£p CatBoost (ho·∫∑c kh√¥ng c√≥ encoder), l·∫•y t·ª´ sample_data
#         options = sample_data.get(col_name, [])

#     # N·∫øu kh√¥ng t√¨m th·∫•y list option, fallback v·ªÅ text input
#     if not options:
#         input_data[col_name] = st.sidebar.text_input(display_name, "Nh·∫≠p gi√° tr·ªã...")
#     else:
#         # Selectbox ch·ªçn gi√° tr·ªã
#         selected_val = st.sidebar.selectbox(
#             label=display_name,
#             options=options,
#             format_func=clean_display_text
#         )
#         input_data[col_name] = selected_val

# # 4. D·ª∞ ƒêO√ÅN
# if st.sidebar.button("D·ª± ƒëo√°n h√†nh vi ti·∫øp theo"):
#     # T·∫°o DataFrame t·ª´ input
#     input_df = pd.DataFrame([input_data])
    
#     # --- QUAN TR·ªåNG: L√ÄM S·∫†CH DATA TR∆Ø·ªöC KHI G·ª¨I V√ÄO MODEL ---
#     # V√¨ d·ªØ li·ªáu m·∫´u ·ªü tr√™n ƒë√£ clean, n√™n ta g·ª≠i data clean v√†o model.
#     # N·∫øu Model c·ªßa b·∫°n train b·∫±ng data b·∫©n (c√≥ kho·∫£ng tr·∫Øng), n√≥ c√≥ th·ªÉ kh√¥ng hi·ªÉu.
#     # Tuy nhi√™n, CatBoost th∆∞·ªùng t·ª± x·ª≠ l√Ω t·ªët.
    
#     try:
#         # Logic d·ª± ƒëo√°n
#         if model_type == 'naive_bayes' and enc:
#             input_encoded = enc.transform(input_df)
#             if np.any(input_encoded < 0): input_encoded[input_encoded < 0] = 0
#             pred_idx = model.predict(input_encoded)
#             pred_label = le.inverse_transform(pred_idx.flatten())[0]
#             proba = model.predict_proba(input_encoded)[0]
#         else:
#             # CatBoost / Random Forest
#             pred_idx = model.predict(input_df)
#             pred_label = le.inverse_transform(pred_idx.flatten())[0]
#             proba = model.predict_proba(input_df)[0]

#         # Hi·ªÉn th·ªã k·∫øt qu·∫£
#         proba_df = pd.DataFrame({
#             'Category': le.classes_,
#             'Probability': proba
#         }).sort_values(by='Probability', ascending=False)

#         st.divider()
#         col1, col2 = st.columns([1, 2])
        
#         with col1:
#             st.success("üéØ K·∫æT QU·∫¢ D·ª∞ B√ÅO")
#             st.metric(label="Kh√°ch h√†ng s·∫Ω mua:", value=clean_display_text(pred_label))
#             st.write(f"ƒê·ªô tin c·∫≠y: **{proba_df.iloc[0]['Probability']*100:.1f}%**")
            
#         with col2:
#             st.subheader("üìä Ph√¢n ph·ªëi x√°c su·∫•t")
#             fig = px.bar(
#                 proba_df, x='Category', y='Probability', 
#                 color='Probability', color_continuous_scale='Teal', text_auto='.1%'
#             )
#             st.plotly_chart(fig, use_container_width=True)

#     except Exception as e:
#         st.error(f"L·ªói khi d·ª± b√°o: {e}")
#         st.info("G·ª£i √Ω: H√£y ƒë·∫£m b·∫£o d·ªØ li·ªáu input (ƒë√£ clean) kh·ªõp v·ªõi d·ªØ li·ªáu l√∫c train model.")
# else:
#     st.info("üëà Ch·ªçn th√¥ng tin b√™n tr√°i v√† b·∫•m 'D·ª± ƒëo√°n'")
import streamlit as st
import pandas as pd
import numpy as np
import joblib
import plotly.express as px

# ================================
# 1. C·∫§U H√åNH TRANG
# ================================
st.set_page_config(page_title="D·ª± ƒëo√°n Category k·∫ø ti·∫øp", layout="wide")
st.title("üõçÔ∏è H·ªá th·ªëng g·ª£i √Ω danh m·ª•c s·∫£n ph·∫©m ti·∫øp theo (Naive Bayes)")
st.markdown("D·ª± ƒëo√°n **Category** m√† kh√°ch h√†ng c√≥ kh·∫£ nƒÉng mua ti·∫øp theo.")

# ================================
# 2. LOAD MODEL
# ================================
@st.cache_resource
def load_model():
    try:
        artifacts = joblib.load("bayes_recommendation_model.pkl")
        return artifacts
    except:
        return None

artifacts = load_model()

if artifacts is None:
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y file bayes_recommendation_model.pkl")
    st.stop()

model = artifacts["model"]
enc = artifacts["feature_encoder"]
le = artifacts["label_encoder"]
feature_names = artifacts["feature_names"]

# ================================
# 3. GIAO DI·ªÜN NH·∫¨P LI·ªÜU
# ================================
st.sidebar.header("Nh·∫≠p th√¥ng tin giao d·ªãch hi·ªán t·∫°i")

column_alias = {
    'current_category': 'Danh m·ª•c ch√≠nh',
    'current_subcategory': 'Danh m·ª•c ph·ª•',
    'current_articletype': 'Lo·∫°i s·∫£n ph·∫©m chi ti·∫øt',
    'customer_gender': 'Gi·ªõi t√≠nh kh√°ch h√†ng',
    'age_group': 'Nh√≥m tu·ªïi',
    'province': 'T·ªânh th√†nh'
}

input_data = {}

def clean_display(text):
    return str(text).strip().title()

# Sinh input t·ª´ encoder (ch√≠nh x√°c 100%)
for idx, col in enumerate(feature_names):
    options = list(enc.categories_[idx])  # l·∫•y th·∫≥ng t·ª´ model
    selected = st.sidebar.selectbox(
        column_alias.get(col, col),
        options=options,
        format_func=clean_display
    )
    input_data[col] = selected

# ================================
# 4. D·ª∞ ƒêO√ÅN
# ================================
if st.sidebar.button("üîÆ D·ª± ƒëo√°n"):
    try:
        df_input = pd.DataFrame([input_data])

        # Encode
        X_encoded = enc.transform(df_input)

        # Predict
        pred_idx = model.predict(X_encoded)[0]
        pred_label = le.inverse_transform([pred_idx])[0]

        proba = model.predict_proba(X_encoded)[0]

        # Chu·∫©n b·ªã dataframe hi·ªÉn th·ªã probability
        proba_df = pd.DataFrame({
            "Category": le.classes_,
            "Probability": proba
        }).sort_values("Probability", ascending=False)

        # ======================
        # HI·ªÇN TH·ªä K·∫æT QU·∫¢
        # ======================
        st.divider()
        col1, col2 = st.columns([1, 2])

        with col1:
            st.success("üéØ K·∫øt qu·∫£ d·ª± ƒëo√°n")
            st.metric("Kh√°ch c√≥ kh·∫£ nƒÉng mua:", clean_display(pred_label))
            st.write(f"ƒê·ªô tin c·∫≠y: **{proba_df.iloc[0]['Probability']*100:.1f}%**")

        with col2:
            st.subheader("üìä X√°c su·∫•t chi ti·∫øt")
            fig = px.bar(
                proba_df,
                x="Category",
                y="Probability",
                text_auto=".2%",
                color="Probability",
            )
            st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"L·ªói d·ª± ƒëo√°n: {e}")

else:
    st.info("üëà Nh·∫≠p th√¥ng tin b√™n tr√°i v√† nh·∫•n **D·ª± ƒëo√°n**")
